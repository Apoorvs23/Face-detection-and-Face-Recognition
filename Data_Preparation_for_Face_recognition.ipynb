{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Read and show video stream,Capture images\n",
    "### 2.Detect facing using haarcascade and show bounding box(haarcascade)\n",
    "### 3.Flatten the largest face image(gray scale) as to save memory and save in numpy array\n",
    "### 4.Repeat the above for multiple face to generate training data\n",
    "### 5. If there are multiple faces in frame/screen we would take largest face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### f=x,y,w,h   \n",
    "if there are more than one faces then we need to select the area with largest face so sorting is required which will be do sort all the faces over Area calulated WxH so F[2]*F[3] (key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Init Camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "skip = 0\n",
    "face_data = [] #array\n",
    "dataset_path = './data/'\n",
    "file_name = input(\"Enter the name of person whose face we are scanning\")\n",
    "while True:\n",
    "\tret,frame = cap.read()\n",
    "\n",
    "\tif ret==False:\n",
    "\t\tcontinue\n",
    "\n",
    "\tgray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\t\n",
    "\n",
    "\tfaces = face_cascade.detectMultiScale(frame,1.3,5) # faces will list of tuples/faces as faces is tupple-[(10,30,20,40),(12,14,15,67)] represeing [(x,y,w,h)]\n",
    "\t#if len(faces)==0:\n",
    "\t\t#continue\n",
    "\t#print(faces) # it will print matrix\n",
    "\t\n",
    "\tfaces = sorted(faces,key=lambda f:f[2]*f[3])\n",
    "\n",
    "\t#Pick the largest face(because it is the largest face according to area f[2]*f[3])\n",
    "\n",
    "\tfor face in faces[-1:]: # -1 means last face : till the end , so only 1 face will be captured which is last one\n",
    "\t\tx,y,w,h = face\n",
    "\t\tcv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2) # drawing rectangle on the frame\n",
    "\n",
    "\t\t#Extract (Crop out the required face) : region of Interest\n",
    "\t\toffset = 10 # means padding of 10 pixels to boundary\n",
    "\t\tface_section = frame[y-offset:y+h+offset,x-offset:x+w+offset]# frame[y,x]  in frame first axis is y axis and second axis is x axis.\n",
    "\t\tface_section = cv2.resize(face_section,(100,100)) # resizing it into 100x100 Pixels\n",
    "        #store every 10th face\n",
    "\t\tskip += 1\n",
    "\t\tif skip%10==0:\n",
    "\t\t\tface_data.append(face_section)\n",
    "\t\t\tprint(len(face_data))#count of the face\n",
    "\n",
    "\n",
    "\tcv2.imshow(\"Frame\",frame)\n",
    "\tcv2.imshow(\"Face Section\",face_section)\n",
    "\n",
    "\tkey_pressed = cv2.waitKey(1) & 0xFF\n",
    "\tif key_pressed == ord('q'):\n",
    "\t\tbreak\n",
    "\n",
    "#convert our face list into numpy array\n",
    "face_data = np.asarray(face_data)\n",
    "face_data = face_data.reshape((face_data.shape[0],-1))# no. of rows= no. of faces and columns should be fighured out automatically\n",
    "print(face_data.shape)\n",
    "\n",
    "# Save this data into file system\n",
    "np.save(dataset_path+file_name+'.npy',face_data)#data/a.npy or data/b.npy\n",
    "print(\"Data Successfully save at \"+dataset_path+file_name+'.npy') # 2nd portion is string\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# the shape s 14,30000. 30000 because we took rgb channel because 3 is multiplied for RGB frame\n",
    "# if you took gray_frame then dimension would be 14,10000\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
